---
title: Impact Model Validation
tags:
  - impact-model
  - video-content
  - strategy
---

<span style="color:green"> Recorded</span> 



# P2P Script: 5.5 Validating Your Impact Model

#CTX program:p2p | example:micro | visual:3 | cta:off | tag_line:on

---

## P2P FRAMING

p2p 5.5 impact-model-validation 1webm

**[MAIN PANEL: Social Lean Canvas - Impact Model section highlighted]**

**Script (spoken):**
<span style="color:red">**CLAP**</span> 
You're about to work through the Core content on impact model validation. This covers why impact validation matters, what to validate across your causal chain, and three validation approaches: research, experiments, and strategic partnership.


**[VISUAL TEXT: Research | Experiments | Partnership | Three approaches]**

**Tag line:** **Prove your theory of change.**

---

**[INSERT CORE CONTENT: Validating Your Impact Model]**

---

## P2P COMMENTARY

p2p 5.5 impact-model-validation 2.webm

**[MAIN PANEL: Text overlay - "Impact Validation for PPVs"]**

**Script (spoken):**

The Core Framework just walked you through impact model validation. Now let's talk about what this looks like for P2P Ventures.

**Tag line:** **P2P impact validation.**

---

### Purpose Spectrum and Validation Depth

**[MAIN PANEL: Spectrum from light to deep impact focus]**

Your validation depth should match where you sit on the impact spectrum.

**[VISUAL TEXT: Personal transformation ← → Systemic change]**

If you're not deeply impact-focused, you don't need the full research-experiments-partnership validation process the Core Framework outlined. But you're not off the hook entirely.

You still need to validate that you model will deliver on your purpose
Whatever your purpose is - freedom, better work-life balance, serving a community you care about - can this business model actually deliver it?

If your purpose is spending more time with family, but your business model requires sixty-hour weeks for years, it won't deliver. Validate your purpose assumptions early so you don't make a big mistake. 

**[VISUAL TEXT: Does model deliver your purpose? | Honest check required]**

Also, **Design is Never Neutral** - assess your unintended consequences.**

You should have worked on understanding possible unintended consequences in the improving your business model section. If there are risks of unintended consequences that you need to remove from the model then design experiments to test them now. 


**[VISUAL TEXT: Design never neutral | validate unintended consequences risk]**


---

### Deep Impact Validation - Lightweight Approaches

**[MAIN PANEL: Deep impact validation framework]**

If you're on the deeper end of the impact spectrum, you need more rigorous validation. But as we covered in improving your impact model, you designed for your capacity. You chose efficient intervention points. You considered partnership.

**[VISUAL TEXT: Efficiency | Design for capacity | Three approaches]**

Now you can validate these designs using lightweight approaches that fit your constraints.

**Tag line:** **Validate efficiently.**

---

#### Common Risk: Too Much to Validate

**[MAIN PANEL: Validation cost diagram]**

Remember when we discussed how the more complex your model, the more difficult and expensive it is to validate. Now that you are needing to plan your validation effort, it is a good time to reassess the model and consider whether it could be simplified and still achieve the outcomes that you are trying to create.  

Before you commit to validating something, ask: Is this piece important enough to validate? Or should could we remove it from the model and still deliver what you want?

**[VISUAL TEXT: Every validation = cost | Only validate what matters]**

### Prioritize the most important risks

When you know what you need to validate, prioritize validating the core assumptions that determine whether your impact model works. Let the rest emerge as you make progress.

**Tag line:** **Validate what matters most.**

---

#### Three Approaches

**[MAIN PANEL: Research, Experiments, Partnership - equal weight]**

The Core Framework showed three validation approaches:

**Research** to validate causal logic and leverage existing knowledge.

**Experiments** to prove your specific activities create predicted outcomes.

**Partnership** to leverage validated models or collaborate on validation.

**[VISUAL TEXT: Research | Experiments | Partnership | Choose what fits]**

Use the approach that's most efficient for each assumption you need to validate.



---

#### Example: Ridwell's Impact Validation

**[MAIN PANEL: Ridwell impact validation journey]**

Let's look at how Ridwell could have approached impact validation with lightweight methods.

Their customer model validation proved customers would pay for hard-to-recycle item collection. People value the service.

But impact model validation is different. Beyond proving that people will pay for it, there are a couple of key things that need to be true for their impact model to work:

**First: The issue is real.** That the lack of recycling solutions for hard-to-recycle items causes significant environmental harm. How much waste goes to landfill unnecessarily? What's the environmental consequence of this?

**Second: Their solution makes meaningful impact.** That their collection and proper routing actually reduces this harm measurably.

**[VISUAL TEXT: Issue real? | Solution impactful?]**

They could validate this through partnerships with other players in the waste system. Partner with municipal waste managers to understand current hard-to-recycle waste volumes. Partner with specialized recyclers to understand what happens to materials when properly routed versus landfilled.

These partnerships give them data on issue severity without needing to commission their own studies. And the same partners can help measure impact when their solution is operational.

This is lightweight validation. They're not building comprehensive waste system models. They're not doing primary environmental research. They're leveraging existing knowledge and relationships to validate their core impact assumptions.

**Tag line:** **Partner to validate.**

They could also utilize AI tools to research studies into the environmental impacts of dumping the hard to recycle items, understand what approaches others have taken? And what outcomes have been reported?

All of these things reduce the cost and accelerate the progress of their validation efforts


**[VISUAL TEXT: Research models | Analyze outcomes | Generate approaches]**

**Tag line:** **AI speeds research.**

---

### Your Turn
**[MAIN PANEL: Impact Model section on canvas]**

Now apply this to your own impact validation.

First, clarify where you sit on the purpose spectrum. How deep does your impact validation need to go?

If you're deep on impact, use the three approaches strategically. Research what's already known. Design lightweight experiments. Consider partnerships that let you validate efficiently.

**[VISUAL TEXT: Match validation to depth | Essentials for light | Rigorous for deep]**

**Create your validation plan document** as outlined in the Core content section. What assumptions need testing? Which approach fits each one - research, experiments, or partnership? What would prove it right or wrong? What's your timeline?
<span style="color:red">**CLAP**</span> 
**Tag line:** **Create your plan.**

---

**END OF SCRIPT**

p2p 5.5 impact-model-validation 1.webm.02.mp4.webm
1
00:00:00,000 --> 00:00:04,320
You're about to work through the core
content on impact model validation.

2
00:00:04,540 --> 00:00:08,015
This covers why impact model
validation matters, what to

3
00:00:08,015 --> 00:00:09,785
validate across your causal chain.

4
00:00:10,342 --> 00:00:14,485
Three validation approaches, research
experiments and strategic partnerships.



p2p 5.5 impact-model-validation 2.webm.02.mp4.webm

1
00:00:00,049 --> 00:00:03,199
The core framework just walked you
through impact model validation.

2
00:00:03,889 --> 00:00:06,079
Now let's talk about what this
looks like for your venture.

3
00:00:07,010 --> 00:00:10,970
Your validation depth should match
where you sit on the impact spectrum.

4
00:00:11,521 --> 00:00:15,100
If you're not deeply impact focused,
you don't need the full research

5
00:00:15,100 --> 00:00:19,428
experiments, partnerships, validation
process that the core framework outlined,

6
00:00:19,938 --> 00:00:21,618
but you're not off the hook entirely.

7
00:00:21,993 --> 00:00:25,233
You still need to validate that your
model will deliver on your purpose.

8
00:00:25,401 --> 00:00:29,631
Whatever your purpose is, freedom,
better work life balance, serving a

9
00:00:29,631 --> 00:00:33,304
community you care about, can this
business model actually deliver it?

10
00:00:34,211 --> 00:00:38,132
If your purpose requires spending more
time with your family, but your business

11
00:00:38,132 --> 00:00:43,412
model's gonna require 60 hours a week for
years, it won't deliver on your purpose.

12
00:00:43,802 --> 00:00:47,642
Validate your purpose assumptions early
so that you don't make a big mistake.

13
00:00:48,519 --> 00:00:50,679
Also, remember, design is never neutral.

14
00:00:51,002 --> 00:00:53,057
Assess your unintended consequences.

15
00:00:53,450 --> 00:00:57,500
You should have worked on understanding
possible unintended consequences in the

16
00:00:57,500 --> 00:00:59,270
improving your business model section.

17
00:00:59,732 --> 00:01:02,942
If there are risks of unintended
consequences that you need to

18
00:01:02,942 --> 00:01:06,027
remove from your model, then
design experiments to test them.

19
00:01:06,087 --> 00:01:06,307
Now

20
00:01:07,145 --> 00:01:09,769
If you're on the deeper end
of the impact spectrum, you

21
00:01:09,769 --> 00:01:11,419
need more rigorous validation.

22
00:01:11,835 --> 00:01:14,307
But as we covered in
improving your impact model.

23
00:01:14,576 --> 00:01:16,586
You will have designed for your capacity.

24
00:01:17,133 --> 00:01:20,038
You will have chosen efficient
intervention points and

25
00:01:20,038 --> 00:01:22,333
considered partnership instead
of doing it all yourself.

26
00:01:23,097 --> 00:01:26,367
Now you can validate these designs
using lightweight approaches

27
00:01:26,367 --> 00:01:27,717
that fit your constraints.

28
00:01:28,703 --> 00:01:33,173
Remember when we discussed how the more
complex your model, the more difficult

29
00:01:33,173 --> 00:01:37,546
and expensive it is to validate Now that
you're needing to plan your validation

30
00:01:37,546 --> 00:01:42,108
effort, it's a good time to reassess the
model and consider whether it could be

31
00:01:42,108 --> 00:01:46,059
simplified and still achieve the same
outcomes that you're trying to create.

32
00:01:46,403 --> 00:01:50,021
before you commit to validating
something, ask, is this piece

33
00:01:50,021 --> 00:01:51,641
important enough to validate?

34
00:01:52,105 --> 00:01:55,926
Or could we remove it from the model
and still deliver what we want?

35
00:01:56,801 --> 00:01:58,841
When you know what you need to validate.

36
00:01:58,901 --> 00:02:02,471
Prioritize validating the core
assumptions that determine whether

37
00:02:02,471 --> 00:02:04,296
your impact model works first.

38
00:02:04,929 --> 00:02:07,479
Let the rest emerge as you make progress.

39
00:02:08,499 --> 00:02:11,541
The core framework showed us
three validation approaches.

40
00:02:11,576 --> 00:02:16,967
Research to validate causal logic and
leverage existing knowledge experiments

41
00:02:16,967 --> 00:02:19,097
to prove your specific activities.

42
00:02:19,097 --> 00:02:20,567
Create predicted outcomes.

43
00:02:21,077 --> 00:02:24,643
partnership to leverage other
people's validated models and

44
00:02:24,643 --> 00:02:26,263
to collaborate on validation.

45
00:02:27,124 --> 00:02:31,581
Use the approach that's most efficient for
each assumption that you need to validate.

46
00:02:32,312 --> 00:02:35,396
Let's look at how Red Well could
have approached impact model

47
00:02:35,396 --> 00:02:37,466
validation with lightweight methods.

48
00:02:37,853 --> 00:02:41,213
The customer model validation
will have proved that customers

49
00:02:41,213 --> 00:02:43,013
will pay for hard to recycle.

50
00:02:43,013 --> 00:02:43,973
Item collection.

51
00:02:44,124 --> 00:02:48,816
People value the service, but impact model
validation is different beyond proving

52
00:02:48,816 --> 00:02:52,957
that people will pay for it, there is a
couple of key things that need to be true

53
00:02:52,957 --> 00:02:54,877
for their impact model to actually work.

54
00:02:55,549 --> 00:02:59,692
First, the issue is real, that
the lack of recycling solutions

55
00:02:59,692 --> 00:03:03,622
for hard to recycle items causes
significant environmental harm.

56
00:03:03,967 --> 00:03:07,357
How much waste does actually
go into landfill unnecessarily?

57
00:03:08,045 --> 00:03:09,550
environmental consequence of this?

58
00:03:10,491 --> 00:03:15,277
Second, their solution makes meaningful
impact That their collection and proper

59
00:03:15,277 --> 00:03:19,947
routing of waste items actually reduces
the environmental harm measurably.

60
00:03:20,559 --> 00:03:23,169
They could validate this
through partnerships with other

61
00:03:23,169 --> 00:03:24,369
players in the waste system.

62
00:03:24,836 --> 00:03:28,246
Partner with municipal waste
managers to understand current,

63
00:03:28,246 --> 00:03:30,106
hard to recycle waste volumes.

64
00:03:30,265 --> 00:03:34,899
Partner with specialized recyclers to
understand what happens to materials when

65
00:03:34,899 --> 00:03:37,089
they're properly routed versus landfill.

66
00:03:37,431 --> 00:03:40,938
these partnerships would give them
data on issue severity without them

67
00:03:40,938 --> 00:03:42,888
needing to commission their own studies.

68
00:03:43,035 --> 00:03:46,349
And at the same time, partners
could help measure impact when their

69
00:03:46,349 --> 00:03:47,969
solution's actually operational.

70
00:03:48,610 --> 00:03:50,410
This is lightweight validation.

71
00:03:50,590 --> 00:03:53,350
They're not building
comprehensive waste system models.

72
00:03:53,849 --> 00:03:56,699
They're not doing primary
environmental research.

73
00:03:56,964 --> 00:04:00,324
They're leveraging existing knowledge
and relationships to validate

74
00:04:00,324 --> 00:04:02,004
their core impact assumptions.

75
00:04:02,764 --> 00:04:06,634
They could also utilize AI tools
to research studies into the

76
00:04:06,634 --> 00:04:10,944
environmental impacts of dumping
hard to recycle items, understand

77
00:04:10,944 --> 00:04:14,586
what approaches others have taken
and what outcomes have been reported.

78
00:04:15,503 --> 00:04:19,043
All of these things would reduce
the cost and accelerate the progress

79
00:04:19,043 --> 00:04:20,453
of their validation efforts.

80
00:04:21,443 --> 00:04:23,513
Now apply this to your own validation.

81
00:04:23,999 --> 00:04:26,635
First, clarify where you
sit on the purpose spectrum.

82
00:04:27,051 --> 00:04:30,081
How deep does your impact
validation need to actually go?

83
00:04:30,488 --> 00:04:34,049
If you're going deep on impact, use
the three approaches strategically,

84
00:04:34,198 --> 00:04:35,788
research what's already known.

85
00:04:36,028 --> 00:04:37,738
Design lightweight experiments.

86
00:04:37,828 --> 00:04:40,343
Consider partnerships that
let you validate efficiently.

87
00:04:41,694 --> 00:04:46,044
Create your own validation plan document
as outlined in the core content section.

88
00:04:46,504 --> 00:04:50,229
What assumptions need testing,
Which approach fits each one?

89
00:04:50,529 --> 00:04:52,599
Research, experiments, or partnership.

90
00:04:52,962 --> 00:04:54,518
What would prove it right or wrong?

91
00:04:55,015 --> 00:04:57,015
What's your timeline and resource needs?

