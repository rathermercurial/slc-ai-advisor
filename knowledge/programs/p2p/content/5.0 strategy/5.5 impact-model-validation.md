---
title: Impact Model Validation
tags:
  - impact-model
  - video-content
  - strategy
---

<span style="color:green"> Recorded</span> 



# P2P Script: 5.5 Validating Your Impact Model

#CTX program:p2p | example:micro | visual:3 | cta:off | tag_line:on

---

## P2P FRAMING

p2p 5.5 impact-model-validation 1webm

**[MAIN PANEL: Social Lean Canvas - Impact Model section highlighted]**

**Script (spoken):**
<span style="color:red">**CLAP**</span> 
You're about to work through the Core content on impact model validation. This covers why impact validation matters, what to validate across your causal chain, and three validation approaches: research, experiments, and strategic partnership.


**[VISUAL TEXT: Research | Experiments | Partnership | Three approaches]**

**Tag line:** **Prove your theory of change.**

---

**[INSERT CORE CONTENT: Validating Your Impact Model]**

---

## P2P COMMENTARY

p2p 5.5 impact-model-validation 2.webm

**[MAIN PANEL: Text overlay - "Impact Validation for PPVs"]**

**Script (spoken):**

The Core Framework just walked you through impact model validation. Now let's talk about what this looks like for P2P Ventures.

**Tag line:** **P2P impact validation.**

---

### Purpose Spectrum and Validation Depth

**[MAIN PANEL: Spectrum from light to deep impact focus]**

Your validation depth should match where you sit on the impact spectrum.

**[VISUAL TEXT: Personal transformation ← → Systemic change]**

If you're not deeply impact-focused, you don't need the full research-experiments-partnership validation process the Core Framework outlined. But you're not off the hook entirely.

You still need to validate that you model will deliver on your purpose
Whatever your purpose is - freedom, better work-life balance, serving a community you care about - can this business model actually deliver it?

If your purpose is spending more time with family, but your business model requires sixty-hour weeks for years, it won't deliver. Validate your purpose assumptions early so you don't make a big mistake. 

**[VISUAL TEXT: Does model deliver your purpose? | Honest check required]**

Also, **Design is Never Neutral** - assess your unintended consequences.**

You should have worked on understanding possible unintended consequences in the improving your business model section. If there are risks of unintended consequences that you need to remove from the model then design experiments to test them now. 


**[VISUAL TEXT: Design never neutral | validate unintended consequences risk]**


---

### Deep Impact Validation - Lightweight Approaches

**[MAIN PANEL: Deep impact validation framework]**

If you're on the deeper end of the impact spectrum, you need more rigorous validation. But as we covered in improving your impact model, you designed for your capacity. You chose efficient intervention points. You considered partnership.

**[VISUAL TEXT: Efficiency | Design for capacity | Three approaches]**

Now you can validate these designs using lightweight approaches that fit your constraints.

**Tag line:** **Validate efficiently.**

---

#### Common Risk: Too Much to Validate

**[MAIN PANEL: Validation cost diagram]**

Remember when we discussed how the more complex your model, the more difficult and expensive it is to validate. Now that you are needing to plan your validation effort, it is a good time to reassess the model and consider whether it could be simplified and still achieve the outcomes that you are trying to create.  

Before you commit to validating something, ask: Is this piece important enough to validate? Or should could we remove it from the model and still deliver what you want?

**[VISUAL TEXT: Every validation = cost | Only validate what matters]**

### Prioritize the most important risks

When you know what you need to validate, prioritize validating the core assumptions that determine whether your impact model works. Let the rest emerge as you make progress.

**Tag line:** **Validate what matters most.**

---

#### Three Approaches

**[MAIN PANEL: Research, Experiments, Partnership - equal weight]**

The Core Framework showed three validation approaches:

**Research** to validate causal logic and leverage existing knowledge.

**Experiments** to prove your specific activities create predicted outcomes.

**Partnership** to leverage validated models or collaborate on validation.

**[VISUAL TEXT: Research | Experiments | Partnership | Choose what fits]**

Use the approach that's most efficient for each assumption you need to validate.



---

#### Example: Ridwell's Impact Validation

**[MAIN PANEL: Ridwell impact validation journey]**

Let's look at how Ridwell could have approached impact validation with lightweight methods.

Their customer model validation proved customers would pay for hard-to-recycle item collection. People value the service.

But impact model validation is different. Beyond proving that people will pay for it, there are a couple of key things that need to be true for their impact model to work:

**First: The issue is real.** That the lack of recycling solutions for hard-to-recycle items causes significant environmental harm. How much waste goes to landfill unnecessarily? What's the environmental consequence of this?

**Second: Their solution makes meaningful impact.** That their collection and proper routing actually reduces this harm measurably.

**[VISUAL TEXT: Issue real? | Solution impactful?]**

They could validate this through partnerships with other players in the waste system. Partner with municipal waste managers to understand current hard-to-recycle waste volumes. Partner with specialized recyclers to understand what happens to materials when properly routed versus landfilled.

These partnerships give them data on issue severity without needing to commission their own studies. And the same partners can help measure impact when their solution is operational.

This is lightweight validation. They're not building comprehensive waste system models. They're not doing primary environmental research. They're leveraging existing knowledge and relationships to validate their core impact assumptions.

**Tag line:** **Partner to validate.**

They could also utilize AI tools to research studies into the environmental impacts of dumping the hard to recycle items, understand what approaches others have taken? And what outcomes have been reported?

All of these things reduce the cost and accelerate the progress of their validation efforts


**[VISUAL TEXT: Research models | Analyze outcomes | Generate approaches]**

**Tag line:** **AI speeds research.**

---

### Your Turn
**[MAIN PANEL: Impact Model section on canvas]**

Now apply this to your own impact validation.

First, clarify where you sit on the purpose spectrum. How deep does your impact validation need to go?

If you're deep on impact, use the three approaches strategically. Research what's already known. Design lightweight experiments. Consider partnerships that let you validate efficiently.

**[VISUAL TEXT: Match validation to depth | Essentials for light | Rigorous for deep]**

**Create your validation plan document** as outlined in the Core content section. What assumptions need testing? Which approach fits each one - research, experiments, or partnership? What would prove it right or wrong? What's your timeline?
<span style="color:red">**CLAP**</span> 
**Tag line:** **Create your plan.**

---

**END OF SCRIPT**

p2p 5.5 impact-model-validation 1.webm.02.mp4.webm
1
